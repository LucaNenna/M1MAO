{"cells": [{"cell_type": "markdown", "metadata": {"editable": false, "deletable": false}, "source": ["# TP 8: Approximation des valeurs propres du Laplacien #\n", "\n", "\n", "## 1. Introduction au calcul de valeurs propres ##\n", "$\\newcommand{\\sca}[2]{\\langle #1|#2\\rangle}\n", "\\newcommand{\\abs}[1]{|#1|}\n", "\\newcommand{\\nr}[1]{\\|#1\\|}\n", "\\newcommand{\\Rsp}{\\mathbb{R}}\n", "\\newcommand{\\hdots}{\\dots}$\n", "Dans toutes la suite, on suppose que $A$ est une matrice diagonalisable sur $\\Rsp$, de taille $N\\times N$, $\\lambda_1,\\hdots \\lambda_N$ sont ses valeurs propres et $w_1,\\hdots,w_N$ est une base de vecteurs propres associ\u00e9s tels que $\\nr{w_i} = 1$. \n", "\n", "**Q1.** (M\u00e9thode de la puissance) On suppose que $\\abs{\\lambda_N} > \\abs{\\lambda_i}$ pour tout $i\\neq N$. Soit $x^{(0)} = \\sum_i \\alpha_i w_i \\in\\Rsp^N$ un vecteur tel que $\\alpha_N \\neq 0$. On d\u00e9finit une par r\u00e9currence $x^{(k+1)} = \\dfrac{A x^{(k)}}{\\nr{A x^{(k)}}}$. \n", "\n", "- D\u00e9montrer que pour tout $k\\geq 1$, $x^{(k)} = \\dfrac{(A^k x^{(0)})}{\\nr{A^k x^{(0)}}}$.\n", "- En d\u00e9duire que \n", "$$\n", "\\begin{aligned}\n", "&\\lim_{k\\to +\\infty} \\min(\\nr{x^{(k)} - w_N}, \\nr{x^{(k)} + w_N}) = 0 \\\\\n", "& \\lim_{k\\to+\\infty} \\nr{A x^{(k)} - \\lambda_N x^{(k)}} = 0\n", "\\end{aligned}$$\n", "\n", "**Q2.** (M\u00e9thode de la puissance inverse) On suppose $0 < \\abs{\\lambda_1} < \\abs{\\lambda_i}$ pour tout $i\\neq 1$. Soit $x^{(0)} = \\sum_i \\alpha_i w_i \\in\\Rsp^N$ tel que $\\alpha_1 \\neq 0$, et $x^{(k+1)} = \\frac{A^{-1} x^{(k)}}{\\nr{A^{-1} x^{(k)}}}$. D\u00e9duire de la question pr\u00e9c\u00e9dente que\n", "$$\n", "\\begin{aligned}\n", "&\\lim_{k\\to +\\infty} \\min(\\nr{x^{(k)} - w_1}, \\nr{x^{(k)} + w_1}) = 0 \\\\\n", "& \\lim_{k\\to+\\infty} \\nr{A x^{(k)} - \\lambda_1 x^{(k)}} = 0\n", "%& \\lim_{k\\to+\\infty} \\sca{A^{-1} x^{(k)}}{x^{(k)}} = \\frac{1}{\\lambda_1}\n", "\\end{aligned}$$\n", "\n", "**Q3.** Soit $B$ diagonalisable de vecteurs propres $\\lambda_1,\\hdots,\\lambda_N$ et $\\sigma\\in\\Rsp$ tel que $\\exists i_0 \\in \\{1,\\hdots,N\\}$ v\u00e9rifiant $\\abs{\\lambda_{i_0} - \\sigma} < \\abs{\\lambda_i - \\sigma}$ pour tout $i\\neq i_0$. Montrer que la m\u00e9thode de la puissance inverse appliqu\u00e9e \u00e0 $A = B - \\sigma \\mathrm{I}_N$ permet d'approcher la valeur propre $\\lambda_{i_0}$ et le vecteur propre associ\u00e9.\n", "\n", "**Q4.** \u00c9crire une fonction `valeur_propre(B,sigma)` retournant la valeur propre de $B$ la plus proche de $\\sigma$ et le vecteur propre associ\u00e9.\n", "- Pour estimer la valeur propre \u00e0 l'\u00e9tape $k$, on calculera $\\lambda^{(k)} =\\dfrac{ (A x^{(k)})_i} { (x^{(k)}_i)}$ o\u00f9 $i = \\arg\\max_{1\\leq j\\leq N} \\abs{x^{(k)}_i}$.\n", "- On interrompra les it\u00e9rations d\u00e8s que $\\nr{A x^{(k)} - \\lambda^{(k)} x^{(k)}} \\leq 10^{-10}$\n", "\n", "Tester le calcul avec la matrice $A$ et $\\sigma = 0$, qui discr\u00e9tise l'oppos\u00e9 du Laplacien 1D (avec conditions de Dirichlet), en diff\u00e9rences finies, soit\n", "\n", "$$ A = \\frac{1}{h^2} \\begin{pmatrix} 2 & -1 \\\\\n", "-1 & 2 & 1 \\\\\n", "& \\ddots &\\ddots & \\ddots \\\\\n", "& & -1 & 2 & -1\\\\\n", "& & & -1 & 2 \n", "\\end{pmatrix},$$\n", "\n", "o\u00f9 $h=1/(N+1)$. Les valeurs propres et vecteur propres de $A$ sont donn\u00e9es par \n", "$\\lambda_i = \\frac{4}{h^2} \\sin\\left(\\pi i h\\right)^2$ et \n", "$(w_i)_j = \\sin\\left(\\pi ij h \\right)$ pour $1\\leq i\\leq j\\leq N$. On pourra utiliser la fonction `np.linalg.eigh` pour calculer les autres valeurs propres et v\u00e9rifier la convergence de l'algorithme vers d'autres valeurs propres.\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt \n", "% matplotlib inline\n", "\n", "# <completer>\n"]}, {"cell_type": "markdown", "metadata": {"editable": false, "deletable": false}, "source": ["## 2. Formulation par \u00e9l\u00e9ments finis ## \n", "\n", "$$\n", "\\newcommand{\\LL}{\\mathrm{L}} \n", "\\newcommand{\\dd}{\\mathrm{d}} \n", "\\newcommand{\\Psp}{\\mathbb{P}}\n", "$$\n", "On s'int\u00e9resse \u00e0 la recherche des valeurs propres du laplacien avec conditions de Neumann d'un ouvert $\\Omega\\subseteq \\Rsp^2$ \u00e0 bord r\u00e9gulier par la m\u00e9thode des \u00e9l\u00e9ments finis en 2D, c'est-\u00e0-dire aux couples $(\\lambda,w) \\in \\Rsp\\times V$ o\u00f9 $V = H^1(\\Omega)$ tels que\n", "\n", "$$\\forall v\\in V, a(w,v) = \\lambda \\sca{w}{v}_{\\LL^2(\\Omega)}$$\n", "\n", "o\u00f9 $a(u,v) = \\sca{u}{v}_V = \\int_\\Omega (\\sca{\\nabla u}{\\nabla v} + uv) \\mathrm{d} x.$\n", "Pour discr\u00e9tiser le probl\u00e8me, on consid\u00e8re une famille de triangulation triangulation $T_h$ de $\\Omega$, et on note:\n", "* $V_h$ l'espace des \u00e9l\u00e9ments finis $\\Psp_1$ sur $T_h$, de sorte que $V_h\\subseteq V := H^1(\\Omega)$;\n", "* $N_h :=\\dim(V_h) = $ nombre de sommets dans la triangulation ;\n", "* $H := \\LL^2(\\Omega)$.\n", "\n", "On rappelle enfin qu'un couple $(\\lambda_h,w_h) \\in \\Rsp\\times V_h$ est valeur propre du probl\u00e8me discret si\n", "\n", "$$\n", "\\forall v_h\\in V_h,\\qquad a(w, v_h) = \\lambda_{h} \\sca{w_{h}}{v_h}_{H}.\n", "$$\n", "\n", "\n", "\n", "**Q1.** (Valeurs propres du probl\u00e8me continu) Justifier que les valeurs propres du laplacien (sur l'espace $V$) forment une suite croissante $0 < \\lambda_1 \\leq \\lambda_2 \\leq \\hdots$ tendant vers l'infini.\n", "\n", "Pour tout noeud $x_i$ (= sommet de la triangulation $T_h$), on note $\\phi_i$ la fonction chapeau correspondante, i.e. l'unique fonction $\\phi_i\\in V_h$ telle que $\\phi_i(x_j) = \\delta_{i,j}$. On rappelle que les fonctions $(\\phi_i)_{1\\leq i\\leq N_h}$ forment une base de l'espace $V_h$. \n", "\n", "**Q2.** (Valeurs propres du probl\u00e8me discret)\n", "- Montrer que $\\lambda\\in \\Rsp$ et $w = \\sum_{i} W_i \\phi_i\\neq 0$ est un couple de valeur/vecteur propre pour le probl\u00e8me variationnel discret si et seulement si  $A W = \\lambda B W$\n", "o\u00f9 les matrice $A$ et $B$ sont \u00e0 pr\u00e9ciser. Montrer que ces matrices sont sym\u00e9triques d\u00e9finies positives. \n", "- Montrer qu'il existe  une matrice $C$ triangulaire inf\u00e9rieure dont les \u00e9l\u00e9ments\n", "diagonaux sont strictement positifs telle que $B = C C^T$.\n", "- En d\u00e9duire l'existence de $\\lambda_{1,h}\\leq \\dots \\leq \\lambda_{N_h,h} \\in \\Rsp$ et de $W_{1,h},\\dots,W_{N_h,h} \\in \\Rsp^N$ tels que $A W_{i,h} = \\lambda_{i,h} B W$ et $\\sca{W_{i,h}}{B W_{i,h}}_{\\Rsp^{N_h}} = 0$."]}, {"cell_type": "markdown", "metadata": {"editable": false, "deletable": false}, "source": ["On admet que le bord de $\\Omega$ est suffisamment r\u00e9gulier pour que $C^\\infty(\\bar{\\Omega})$ soit dense dans $H^1(\\Omega)$ (il suffit par exemple que $\\partial \\Omega$ soit de bord $C^1$). De plus, on supposera l'existence d'un op\u00e9rateur $r_h: C^2(\\bar{\\Omega})\\to H^1(\\Omega)$ tel que  pour toute fonction $v\\in C^2(\\bar{\\Omega})$, $\\lim_{h\\to 0} \\nr{r_h(v) - v}_{H^1(\\Omega)} = 0.$ \n", "\n", "*(NB: Cela revient implicitement \u00e0 faire une hypoth\u00e8se sur la triangulation.)*\n", "\n", "**Q3.** (Convergence des valeurs propres) Soit $V' \\subseteq V$ un sous-espace vectoriel de dimension finie engendr\u00e9 par une famille orthonormale $w_1,\\hdots,w_k\\in V$.\n", "- D\u00e9montrer que $\\lim_{h\\to 0} \\max_{1\\leq i\\leq k} \\dd(w_k,V_h) = 0, $\n", "o\u00f9 l'on a pos\u00e9 $\\dd(w,V_h) = \\min_{v\\in V_h} \\nr{v-w}_V$.\n", "- En d\u00e9composant $w\\in W$ dans la base des $(w_i)_{1\\leq i\\leq k}$, prouver que \n", "$\\max_{w \\in V' \\mid \\nr{w} = 1} \\dd(w,V_h) \\leq \\sqrt{k} \\max_{1\\leq i\\leq k} \\dd(w_k,V_h).$\n", "- En utilisant un th\u00e9or\u00e8me du cours, en d\u00e9duire que pour tout $k$, $\\lim_{h\\to 0} \\lambda_{k,h} = \\lambda_k$.\n", "\n", "\n", "**Q4.** Construire les matrices $A$ et $B$ en Python pour une triangulation du carr\u00e9 $\\Omega = [0,1]^2$, avec $h=1/30$ (reprendre le TP pr\u00e9c\u00e9dent). \n", "- Calculer la plus petite valeur propre et le vecteur propre associ\u00e9 en appliquant la fonction \u00e9crite dans le premi\u00e8re partie \u00e0 la matrice $B^{-1} A$. \n", "- Calculer et visualiser les vecteurs propres correspondant aux $k=10$ plus petites valeurs propres en utilisant la fonction `np.linalg.eig`.\n", "- Comment \u00e9volue le nombre d'it\u00e9ration de l'algorithme utilis\u00e9 dans `valeur_propre` lorsque sigma est proche d'une valeur propre multiple ? Justifier ce comportement."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["import matplotlib.tri as tri\n", "\n", "def triangulation_carre(n):\n", "    x,y = np.meshgrid(np.linspace(0.,1.,n),\n", "                      np.linspace(0.,1.,n))\n", "    x = x.reshape(n*n,1)\n", "    y = y.reshape(n*n,1)\n", "    X = np.hstack((x,y))\n", "    T = tri.Triangulation(x.flatten(), y.flatten()).triangles\n", "    return X,T\n", "\n", "def M_elem(S1,S2,S3):\n", "    x1 = S1[0]\n", "    y1 = S1[1]\n", "    x2 = S2[0] \n", "    y2 = S2[1]\n", "    x3 = S3[0]\n", "    y3 = S3[1]\n", "    D = ((x2-x1)*(y3-y1) - (y2-y1)*(x3-x1))\n", "    M=(1.*np.abs(D)/24)*np.ones([3,3])\n", "    M[range(3),range(3)]=1.*np.abs(D)/12\n", "    return M\n", "\n", "def K_elem(S1,S2,S3):\n", "    x1 = S1[0]\n", "    y1 = S1[1]\n", "    x2 = S2[0] \n", "    y2 = S2[1]\n", "    x3 = S3[0]\n", "    y3 = S3[1]\n", "    norm = np.zeros([3, 2])\n", "    norm[0, :] = np.array([y2-y3, x3-x2])\n", "    norm[1, :] = np.array([y3-y1, x1-x3])\n", "    norm[2, :] = np.array([y1-y2, x2-x1])\n", "    D = ((x2-x1)*(y3-y1) - (y2-y1)*(x3-x1))\n", "    K = np.zeros([3,3])\n", "    for i in range(3):\n", "        for j in range(3):\n", "            K[i,j] = np.dot(norm[i,:],norm[j,:])\n", "    return (1./(2*abs(D)))*K\n", "\n", "def masse_et_rigidite(X,T):\n", "    NSom = X.shape[0]\n", "    NTri = T.shape[0]\n", "    K = np.zeros([NSom,NSom])\n", "    M = np.zeros([NSom,NSom])\n", "    for N in range(0,NTri):\n", "        S1=X[T[N,0],:]\n", "        S2=X[T[N,1],:]\n", "        S3=X[T[N,2],:]\n", "        Kel=K_elem(S1, S2, S3)\n", "        Mel=M_elem(S1, S2, S3)\n", "        for i in range(0,3): \n", "            I = T[N,i]\n", "            for j in range(0,3): \n", "                J = T[N,j]\n", "                M[I,J] = M[I,J] + Mel[i,j]\n", "                K[I,J] = K[I,J] + Kel[i,j]\n", "    return M,K\n", "\n", "# <completer>\n", "\n"]}], "metadata": {"celltoolbar": "None", "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.0"}}, "nbformat": 4, "nbformat_minor": 1}