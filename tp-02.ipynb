{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\newcommand{\\nr}[1]{\\|#1\\|}\n",
    "\\newcommand{\\Rsp}{\\mathbb{R}}$$\n",
    "\n",
    "# TP2 : Méthode des différences finies pour $-u'' = f$\n",
    "\n",
    "## Exercice 1. Méthode du gradient et ordre de convergence\n",
    "\n",
    "On veut approcher le problème $-u''=f$ avec conditions de Dirichlet : \n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{aligned}\n",
    "&-u''(x) = f(x) \\hbox{ sur } ]0,1[ \\\\\n",
    "&u(0) = u(1) = 0\n",
    "\\end{aligned}\\right.$$\n",
    "\n",
    "par le système linéaire de dimension finie \n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{aligned}\n",
    "&-\\frac{1}{h^2}(u_{i-1} - 2 u_i + u_{i+1}) = f_i \\hbox{ pour } 1\\leq i\\leq N\\\\\n",
    "&u_{0} = 0, u_{N+1} = 0 \n",
    "\\end{aligned}\\right.,$$\n",
    "\n",
    "où $h = 1/(N+1)$ et $x_j = \\tau j$ pour $0\\leq j\\leq N$ et $f_j = f(t_j)$. \n",
    "\n",
    "D'après le TP1 on sait que si on pose $\\bf U = (u_1,\\dots, u_N)$ et $\\bf F = (f_1,\\dots,f_N)$, le système linéaire peut être écrit sous la forme $A_h \\bf U = \\bf F$, où $A_h$ est une matrice symétrique. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1- La méthode du gradient\n",
    "\n",
    "Soit $\\mathcal J(\\bf u)$ la fonctionelle définie par \n",
    "\\begin{equation}\n",
    "\\mathcal J(\\bf u)=\\dfrac{1}{2}<A_h\\bf u|\\bf u>-<\\bf f| \\bf u>,\n",
    "\\end{equation}\n",
    "où $<\\cdot|\\cdot>$ désigne le produit scalaire euclidien et $A_h\\in\\mathcal M_n(\\mathbb R)$.\n",
    "\n",
    "**Q1)** Calculer $\\nabla \\mathcal J$, $D^2\\mathcal J$ et montrer que si $A_h$ est symétrique et définie positive alors $\\mathcal J$ est convexe. Sachant que si $\\mathcal J$ convexe alors on a le résultat suivant \n",
    "\\begin{equation}\n",
    "\\bf \\bar u \\in\\argmin \\mathcal J \\Longleftrightarrow \\nabla\\mathcal J (\\bf\\bar u)=0\n",
    "\\end{equation}\n",
    "déduire qu'un minimiseur $\\bf \\bar u$ de $\\mathcal J$ est solution de l'équation de Poisson discretisée avec les différences finies ($A_h$ est maintenant la matrice trouvé dans la section précédente). \n",
    "\n",
    "**Q2)** Implementer $\\mathcal J$ et $\\nabla\\mathcal J$ en utilsant les fonctions `J(u,A,f)` et `DJ(u,A,f)`.\n",
    "On rappelle que pour `A,f` donnés, on peut définir une fonction dans la seule variable `u` comme `JN =lambda u : J(u,A,f)`.\n",
    "\n",
    "Soient  $\\bf u_0$ un point de départ,  $\\tau$ le pas de descente et  $\\epsilon$ une tolerance alors \n",
    " l'algorithme du gradient pour une fonctionnelle $\\mathcal J :\\mathbb R^N\\rightarrow \\mathbb R$ s'écrit comme\n",
    "\\begin{equation}\n",
    "\\label{grad}\n",
    "\\bf{u}^{k+1}= \\bf u^k -\\tau \\nabla\\mathcal J(\\bf u_k).\n",
    "\\end{equation}\n",
    "On arrêtera les itérations lorsque $\\parallel \\nabla \\mathcal J_N(\\bf u_k)\\parallel\\leq \\epsilon$.\n",
    "D'après le cours on sait que $\\bf u^k\\rightarrow \\bf \\bar u$ si $\\tau \\in (0,\\dfrac{2}{\\lambda_{max}})$ et le meilleur choix est $\\tau^\\star=\\dfrac{2}{\\lambda_{min}+\\lambda_{max}}$. \n",
    "\n",
    "**Q3)** Implémenter l'algorithme du gradient à travers une fonction de la forme \n",
    "\n",
    "`gradient_fixe(J,DJ,u0,tau,epsilon,iterMax) `\n",
    "\n",
    "prennant en argument la fonctionnelle `J` à minimiser, le gradient `DJ`, la valeur initiale `u0`, le pas `tau`, le nombre maximal d'iterations autorisées `IterMax` et la tolerance `epsilon`. Cette fonction devra retourner:\n",
    "- `u` dernier terme de la suite. \n",
    "\n",
    "- `iter` nombre d'itérations effectuées.\n",
    "\n",
    "- `err` liste de $\\parallel \\nabla \\mathcal J(\\bf u_k)\\parallel$.\n",
    "\n",
    "**Q4)**  Pour $n=20,50,100$. Afficher à l'aide de la fonction `fprintf` le nombre d'itérations pour chaque $N$. Tracer sur la même figure les solutions approchées. On prendra $f(x) = (2\\pi)^2 \\sin(2\\pi x)$, $\\tau=0.1$ et $\\epsilon=10^{-8}$. Tracer en échelle logarithmique `err` en fonction du nombre des itérations. Commenter les résultats.\n",
    "\n",
    "**Q5)** Reprendre l'expérience précédent en utlisant le meilleur choix de $\\tau^\\star$ (pour calculer $\\lambda_{min}$ et $\\lambda_{max}$ on utilisera la fonction `np.linalg.eig(A)` qui retourne les valeurs propres d'une matrice $A$) trouvé au début de l'exercice. Commenter les résultats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2- Ordre de convergence\n",
    "\n",
    "**Q6)** On considère $f(x) = (2\\pi)^2 \\sin(2\\pi x)$, de sorte que la solution de l'équation est donnée par $u(x) = \\sin(2\\pi x)$. Illustrer numériquement le fait que la méthode des différences finies est d'ordre $2$ pour ce problème. On utilisera `np.linalg.solve` pour resoudre le système linéaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3- conditions de Dirichlet non-homogènes\n",
    "\n",
    "On considère maintenant le problème $-u''=f$ avec conditions de Dirichlet non-homogènes : \n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{aligned}\n",
    "&-u''(x) = f(x) \\hbox{ sur } ]0,1[ \\\\\n",
    "&u(0) = a, u(1) = b,\n",
    "\\end{aligned}\\right.$$\n",
    "\n",
    "où $a,b\\in\\Rsp$, par le système linéaire de dimension finie \n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{aligned}\n",
    "&-\\frac{1}{h^2}(u_{i-1} - 2 u_i + u_{i+1}) = f_i \\hbox{ pour } 1\\leq i\\leq N \\\\\n",
    "&u_{0} = a, u_{N+1} = b \n",
    "\\end{aligned}\\right.,$$\n",
    "\n",
    "où $h = 1/(N+1)$ et $x_j = \\tau j$ pour $0\\leq j\\leq n$ et $f_j = f(t_j)$. \n",
    "\n",
    "**Q7)** Mettre ce système sous la forme $A U = F+\\Delta$ où $A$ est la discrétisation habituelle de l'opérateur $u\\mapsto -u''$ (de taille $N\\times N$) et où $\\Delta \\in\\Rsp^N$ est un vecteur à déterminer.\n",
    "\n",
    "**Q8)** Vérifier que dans ce cas aussi la convergence est d'ordre $2$ dans le cas $a=1, b=0, f = (3\\pi/2)^2 \\cos\\left(\\frac{3\\pi}{2} x\\right)$ dont la solution est $x \\mapsto \\cos\\left(\\frac{3\\pi}{2} x\\right)$. Justifier rapidement cet ordre de convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2. Traitement de conditions au bord de Neumann\n",
    "\n",
    "### 2.1- Ordre 1\n",
    "\n",
    "On approche le problème $-u'' + u=f$ avec conditions de Neumann : \n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{aligned}\n",
    "&-u''(x) + u(x) = f(t) \\hbox{ sur } ]0,1[ \\\\\n",
    "&u'(0) = u'(1) = 0\n",
    "\\end{aligned}\\right.$$\n",
    "\n",
    "par le système linéaire de dimension finie \n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{aligned}\n",
    "&\\frac{u_{1} - u_{-1}}{2h} = 0, \\frac{u_{N+2} - u_N}{2h} = 0 \\\\\n",
    "&-\\frac{1}{h^2}(u_{i-1} - 2 u_i + u_{i+1}) +u_i= f_i \\hbox{ pour } 0\\leq i\\leq N+1\n",
    "\\end{aligned}\\right.,$$\n",
    "\n",
    "où $h = 1/(N+1)$, $x_j = h j$ pour $0\\leq j\\leq N+1$, $f_j = f(x_j)$ et $u_{-1},u_{N+2}$ sont deux points fictifs.\n",
    "on remarque bien qu'en utilisant $u_{-1},u_{N+2}$ on a bien une discretisation à l'ordre 2 de $u'$.  \n",
    "\n",
    "\n",
    "\n",
    "**Q9)** Écrire le problème discret  sous la forme $A_h U = F$ où $A_h$ est une matrice de taille $N+2\\times N+2$, où $U = (u_0,\\dots,u_{N+1}) \\in\\Rsp^N$, et où $F = (f_0,\\dots,f_{N+1})$. Implementee une fonction `Ah(N)` cosntruisant la matrice $A_h$.\n",
    "\n",
    "**Q10)**  Montrer que si $V\\in \\Rsp^{N}$ vérifie $A_h V = F$, alors \n",
    "$\\nr{V}_\\infty \\leq \\nr{F}_\\infty$, où $\\nr{F}_\\infty = \\max_{i} |F_i|.$ En déduire que $A_h$ est inversible. *(Indication: considérer l'indice $i_0$ réalisant le maximum dans la définition de $\\nr{V}_\\infty$, et démontrer que $V_{i_0} \\leq F_{i_0} \\leq \\nr{F}_\\infty$.)*\n",
    "\n",
    "**Q11)** Montrer que si $u\\in C^3([0,1])$ est solution du problème continu, et si l'on pose $\\bar{U} = (u(x_0),\\dots, u(x_{N+1}))$, alors $\\nr{A_h \\bar{U} - F}_\\infty \\leq C h$ où $C$ ne dépend que de $u$ (et pas de $h$).\n",
    "\n",
    "**Q12)** En déduire que si $U$ vérifie $A_h U = F$, alors $\\nr{U - \\bar{U}}_\\infty \\leq Ch$.\n",
    "\n",
    "**Q13)** En prenant $f(x) = ((2\\pi)^2 + 1) \\cos(2\\pi x)$ (soit $u(x) = \\cos(2\\pi x)$), Vérifier numériquement que la convergence est d'ordre  $2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2- Application : régularisation de signaux \n",
    "\n",
    "Dans cette partie on s'intéresse à un problème de débruitage. Étant donné un signal 1D $v:[0,1]\\to\\mathbb{R}$ continu et un paramètre $\\alpha > 0$, on cherche à construire un signal régularisé en résolvant l'équation différentielle\n",
    "\n",
    "$$\n",
    "(D)\\hspace{3cm} \\left\\{\\begin{aligned}\n",
    "&-u''(t) + \\alpha (u(t) - v(t)) = 0 \\hbox{ sur } ]0,1[ \\\\\n",
    "&u'(0) = u'(1) = 0\n",
    "\\end{aligned}\\right.,$$\n",
    "\n",
    "que l'on discrétise comme dans la section précédente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14)** Poser $U = (u_0,\\dots, u_{N+1})$ et écrire le système sous la forme $A_h U = F$ où la matrice $A_h$ et le vecteur $F$ sont à construire. Écrire une fonction `A(n,alpha)` construisant la matrice $A_h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Q15)** Écrire une fonction `regularisation(v,alpha)` retournant le vecteur u vérifiant $(D_n)$. Tester la résolution du système à partir du signal $v$ donné ci-dessous (une somme de Gaussiennes auquelles on a rajouté un bruit uniforme),  pour $\\alpha\\in\\{50,100,1000\\}$ et $n=50$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=50\n",
    "t = np.linspace(0,1,n+2)\n",
    "v = 4*np.exp(-500*np.square(t-.8)) + np.exp(-50*np.square(t-.2))\n",
    "v = v + .5*np.random.random(n+2) \n",
    "# compléter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
